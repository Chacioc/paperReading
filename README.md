[STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning](https://openreview.net/pdf?id=_3ELRdg2sgI)

[QA-NatVer: Question Answering for Natural Logic-based Fact Verification](https://arxiv.org/pdf/2310.14198)

[Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation](https://aclanthology.org/2024.acl-long.375.pdf)

用gpt4辅助标注了28k个NL-FOL对训练了一个NL-FOL转化器LOGICLLAMA，达到了GPT4的效果。该论文揭示了现有逻辑推理数据集的不足，提出了3种训练方式和一个数据合成的方法

[Zero-Shot Fact Verification via Natural Logic and Large Language Models](https://arxiv.org/abs/2410.03341)

QA-NatVer的大模型版本，跨语言跟跨数据集都不错

[TABVER: Tabular Fact Verification with Natural Logic](https://arxiv.org/pdf/2411.01093)

QA-NatVer的表格版本，拓展蕴含关系到数字计算上

[LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models](https://aclanthology.org/2024.emnlp-main.128.pdf)

提出一种用于评估和增强大型语言模型的逻辑推理能力的新方法。构建有针对性的演示示例作为上下文或者微调能提升LLM的推理能力（其实提升一般）
